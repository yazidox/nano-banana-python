from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, HttpUrl
import os
import time
import requests
import uvicorn
import replicate

# Initialize FastAPI app
app = FastAPI(title="Glasses Overlay API", version="1.0.0")

# Get allowed origins from environment or use * for development
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "*").split(",")

# Add CORS middleware to allow frontend access
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount the output directory as static files so we can serve the images
app.mount("/output", StaticFiles(directory="output"), name="output")

# Get configuration from environment variables with defaults
REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN")
PORT = int(os.getenv("PORT", "8000"))
HOST = os.getenv("HOST", "0.0.0.0")

# Get the public URL for the API (Railway provides this)
PUBLIC_URL = os.getenv("RAILWAY_PUBLIC_DOMAIN", "localhost:8000")
if not PUBLIC_URL.startswith("http"):
    PUBLIC_URL = f"https://{PUBLIC_URL}" if "railway" in PUBLIC_URL else f"http://{PUBLIC_URL}"

class GlassesRequest(BaseModel):
    image_url: HttpUrl

class GlassesResponse(BaseModel):
    success: bool
    message: str
    image_url: str = None
    local_path: str = None

class GlassesRequest(BaseModel):
    image_url: HttpUrl

class GlassesResponse(BaseModel):
    success: bool
    message: str
    image_url: str = None
    local_path: str = None

def add_glasses_to_image(image_url: str, output_dir: str = "output"):
    """
    Add glasses to a person in an image using Google's nano-banana model via Replicate API.
    Uses the glasses.png file and applies it to the input image.
    Returns the path to the generated image.
    """
    if not REPLICATE_API_TOKEN:
        raise Exception("REPLICATE_API_TOKEN environment variable is required")
    
    # Set the API token as environment variable for replicate
    import os
    os.environ["REPLICATE_API_TOKEN"] = REPLICATE_API_TOKEN
    
    try:
        print(f"Adding glasses with nano-banana model: {image_url}")
        
        # Use the specific glasses URL from Replicate delivery
        glasses_url = "https://replicate.delivery/pbxt/NmRETmL8mnA8T627dXe98QBPJr79uUBFbLotL1qSbbKBjT6c/glasses.png"
        
        # Enhanced prompt for perfect glasses overlay with maximum eye visibility
        prompt = """TASK: Overlay the provided glasses on every detected face in the image.

RULES:
MAKE SURE TO OVERLAY THE GLASSES AKA, IN TOP OF THE NOISE ETC DON4T MAKE NOISE IN TOP OF GLASSES 
1. Keep the original image dimensions exactly. Never crop, cut, or deform the base image.
2. Place the glasses in the natural glasses position on the face.
3. If eyes exist → they must remain clearly visible through the lenses.
4. If eyes do not exist in the original image → still place the glasses naturally on the face, but never draw or invent eyes.
5. Rotate/adjust angle if needed to align with the face and maximize eye visibility when eyes are present.
6. Scale proportionally:
   - Glasses must fit the face naturally.
   - Not larger than the face, not too small.
   - Maintain original proportions (no distortion).
7. Never add anything else — no extra shapes, no edits, no background changes.
8. Never draw temple arms or sidebars — only overlay the glasses frame.
9. Apply to all faces in the image with the same rules.

FINAL NOTE:
The result must be the original image with glasses correctly sized, aligned, and placed on each face.  
If eyes exist, keep them visible.  
If eyes don’t exist, just place glasses naturally, never draw eyes."""
        
        # Use google/nano-banana model
        output = replicate.run(
            "google/nano-banana",
            input={
                "prompt": prompt,
                "image_input": [glasses_url, image_url],
                "output_format": "jpg"
            }
        )
        
        # Download the generated image
        if output:
            print(f"Downloading image from nano-banana...")
            
            # Save the image directly from the result
            timestamp = int(time.time())
            output_filename = f"nano_banana_glasses_{timestamp}.jpg"
            output_path = os.path.join(output_dir, output_filename)
            
            # Write the file to disk
            with open(output_path, "wb") as f:
                f.write(output.read())
            
            print(f"Image saved to: {output_path}")
            return output_filename
        else:
            raise Exception("No image was generated by nano-banana")
            
    except Exception as e:
        print(f"Error processing image with nano-banana: {str(e)}")
        raise e

@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "name": "AI Image Generation API",
        "version": "1.0.0",
        "endpoints": {
            "POST /add-glasses": "Add glasses to an image from URL using Google's nano-banana model",
            "GET /health": "Health check endpoint"
        },
        "models": {
            "nano-banana": "Google's nano-banana model for precise glasses overlay"
        }
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "service": "glasses-overlay-api"}

@app.post("/add-glasses", response_model=GlassesResponse)
async def add_glasses(request: GlassesRequest):
    """
    Add glasses to a person in an image using Google's nano-banana model.
    
    Args:
        request: GlassesRequest with image_url
        
    Returns:
        GlassesResponse with the URL of the processed image
    """
    try:
        # Ensure output directory exists
        os.makedirs("output", exist_ok=True)
        
        # Process the image with nano-banana
        output_filename = add_glasses_to_image(str(request.image_url))
        
        if output_filename:
            # Create the full URL for the generated image
            image_url = f"{PUBLIC_URL}/output/{output_filename}"
            
            return GlassesResponse(
                success=True,
                message="Glasses added successfully with nano-banana!",
                image_url=image_url,
                local_path=f"output/{output_filename}"
            )
        else:
            raise HTTPException(status_code=500, detail="Failed to add glasses")
            
    except requests.exceptions.RequestException as e:
        return GlassesResponse(
            success=False,
            message=f"Failed to download image: {str(e)}"
        )
    except Exception as e:
        error_message = str(e)
        if "REPLICATE_API_TOKEN" in error_message:
            return GlassesResponse(
                success=False,
                message="Replicate API token is required. Please set REPLICATE_API_TOKEN environment variable."
            )
        else:
            return GlassesResponse(
                success=False,
                message=f"Error adding glasses with nano-banana: {error_message}"
            )

if __name__ == "__main__":
    print("Starting AI Image Generation API server...")
    print(f"API will be available at: {PUBLIC_URL}")
    print(f"Documentation available at: {PUBLIC_URL}/docs")
    print(f"Port: {PORT}, Host: {HOST}")
    print("Using nano-banana model for precise glasses overlay")
    if REPLICATE_API_TOKEN:
        print("✓ Replicate API token configured")
    else:
        print("⚠ Replicate API token not set - /add-glasses endpoint will require REPLICATE_API_TOKEN")
    uvicorn.run(app, host=HOST, port=PORT)
